{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd086c6-2098-4680-a24c-8ad82aeaa86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14388\\anaconda3\\envs\\torchenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import nn, optim\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa990e7f-ab9f-4250-b2bf-ffebe59eddef",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc32a670-d10f-4cd5-b9f8-860bffe99cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.1)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.1)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.1):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.1):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc39a129-3832-4ef4-b710-3018ca467104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize a dataset\n",
    "def get_data_loader(city = 'austin', batch_size = 20):\n",
    "    train_dataset  = ArgoverseDataset(city = city, split = 'train')\n",
    "    val_dataset = ArgoverseDataset(city = city, split = 'val')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset,batch_size=batch_size)\n",
    "    return train_dataset, val_dataset, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7747bde3-22dd-4f31-9bb2-2e811680204b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38737"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, train_loader, val_loader = get_data_loader(city = 'austin', batch_size = 64)\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b1ebdc-3841-4f47-93cc-4e07b0a427e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4304"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d16ff-1822-43fc-b83c-04b52f40893a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22ebce9-3cd2-41ba-9de2-9c3094179d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn. Module):\n",
    "    def __init__(self, batch_size = 64, hidden_size = 128, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = 2, hidden_size = self.hidden_size, num_layers = self.num_layers, batch_first = True)\n",
    "        self.FC = nn.Linear(self.hidden_size, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        x = x.float()\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        out = self.FC(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        \n",
    "        weights = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weights.new(self.num_layers, batch_size, self.hidden_size).zero_().float(), # (num_layers, batch_size)\n",
    "                  weights.new(self.num_layers, batch_size, self.hidden_size).zero_().float())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f0ebbd-c423-42fe-85fc-3a985477694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_min_max(city):\n",
    "    _, _, train_loader, val_loader = get_data_loader(city = city, batch_size = len(train_dataset))\n",
    "    diagonal = maxX = minX = maxY = minY = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        sample_batch = torch.concat(sample_batch, axis = 1)\n",
    "        maxX, minX = sample_batch[:,:,0].max(), sample_batch[:,:,0].min()\n",
    "        maxY, minY = sample_batch[:,:,1].max(), sample_batch[:,:,1].min()\n",
    "        diagonal = torch.sqrt((maxX-minX)*(maxX-minX) + (maxY-minY)*(maxY-minY))\n",
    "    return [maxX, minX, maxY, minY, diagonal]\n",
    "\n",
    "def city_min_max_dict():\n",
    "    res = {}\n",
    "    for city in cities:\n",
    "        res[city] = city_min_max(city)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84519941-17c4-4a8e-87d4-564a4d773866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inp, maximum, minimum, how = 'normalize'):\n",
    "    maxX, minX = maximum[:,0], minimum[:,0]\n",
    "    maxY, minY = maximum[:,0], minimum[:,0]\n",
    "    diagonal = torch.sqrt((maxX-minX)*(maxX-minX) + (maxY-minY)*(maxY-minY))\n",
    "    if how == 'normalize':\n",
    "        res = []\n",
    "        for batch, m, d in zip(inp, minimum, diagonal):\n",
    "            res.append(torch.sub(batch, m)/d)\n",
    "        return torch.stack(res).float()\n",
    "    if how == 'reverse':\n",
    "        res = []\n",
    "        for batch, m, d in zip(inp, minimum, diagonal):\n",
    "            res.append(batch*d + m)\n",
    "        return torch.stack(res).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8e2ee2-11cf-4334-bbb4-dd62206262f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (38490250.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in range(2):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, train_loader, val_loader = get_data_loader(city = 'austin', batch_size = 10)\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    sample_batch = torch.concat(sample_batch, axis = 1)\n",
    "        for i in range(2):\n",
    "            inp = sample_batch[:,i*50:(i+1)*50,:]\n",
    "            maximum = inp.max(axis = 1).values+1\n",
    "            minimum = inp.min(axis = 1).values-1\n",
    "            # normalization\n",
    "            normalize(inp, maximum, minimum, how = 'normalize')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "98b82bc1-2fc4-459c-8c38-d90a539cd8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4304, 2])\n",
      "torch.Size([4304])\n",
      "torch.Size([4304, 110, 2])\n",
      "tensor([[ -351.9597,   889.7750],\n",
      "        [ -188.8811,   502.1945],\n",
      "        [ 2123.6430, -1585.9456],\n",
      "        ...,\n",
      "        [ -115.8651, -1262.5304],\n",
      "        [  -78.7036,  -612.1985],\n",
      "        [ -230.1506,  1094.9175]], dtype=torch.float64)\n",
      "tensor([[ -392.2322,   847.1345],\n",
      "        [ -259.6579,   360.4923],\n",
      "        [ 2059.7451, -1693.2593],\n",
      "        ...,\n",
      "        [ -167.2549, -1351.9212],\n",
      "        [ -190.8524,  -674.5488],\n",
      "        [ -280.2172,  1003.6119]], dtype=torch.float64)\n",
      "tensor([[[ -371.9725,   869.6596],\n",
      "         [ -371.9723,   869.6593],\n",
      "         [ -371.9720,   869.6592],\n",
      "         ...,\n",
      "         [ -372.1832,   867.6788],\n",
      "         [ -372.2095,   867.3911],\n",
      "         [ -372.2322,   867.1345]],\n",
      "\n",
      "        [[ -208.8811,   482.1945],\n",
      "         [ -209.0317,   481.6050],\n",
      "         [ -209.2325,   480.8890],\n",
      "         ...,\n",
      "         [ -239.5730,   380.7581],\n",
      "         [ -239.6217,   380.6076],\n",
      "         [ -239.6579,   380.4923]],\n",
      "\n",
      "        [[ 2079.7477, -1673.2593],\n",
      "         [ 2079.7515, -1673.0655],\n",
      "         [ 2079.7451, -1672.7991],\n",
      "         ...,\n",
      "         [ 2103.3735, -1606.6444],\n",
      "         [ 2103.5254, -1606.2513],\n",
      "         [ 2103.6430, -1605.9456]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -137.9115, -1282.5304],\n",
      "         [ -137.9629, -1282.7667],\n",
      "         [ -138.0269, -1283.0435],\n",
      "         ...,\n",
      "         [ -136.4587, -1331.6736],\n",
      "         [ -136.1279, -1331.8128],\n",
      "         [ -135.8651, -1331.9212]],\n",
      "\n",
      "        [[ -170.8524,  -632.1985],\n",
      "         [ -170.2349,  -632.4634],\n",
      "         [ -169.5010,  -632.8046],\n",
      "         ...,\n",
      "         [  -98.8622,  -654.5023],\n",
      "         [  -98.7753,  -654.5277],\n",
      "         [  -98.7036,  -654.5488]],\n",
      "\n",
      "        [[ -250.1506,  1023.6119],\n",
      "         [ -250.2792,  1023.6181],\n",
      "         [ -250.4353,  1023.6272],\n",
      "         ...,\n",
      "         [ -256.5353,  1074.5115],\n",
      "         [ -256.5439,  1074.7406],\n",
      "         [ -256.5513,  1074.9175]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM()\n",
    "opt = optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "total_loss = 0\n",
    "_, _, train_loader, val_loader = get_data_loader(city = 'austin', batch_size = len(train_dataset))\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    sample_batch = torch.concat(sample_batch, axis = 1)\n",
    "    maximum = sample_batch.max(axis = 1).values+20\n",
    "    minimum = sample_batch.min(axis = 1).values-20\n",
    "    maxX, minX = maximum[:,0], minimum[:,0]\n",
    "    maxY, minY = maximum[:,0], minimum[:,0]\n",
    "    print(maximum.shape)\n",
    "    diagonal = torch.sqrt((maxX-minX)*(maxX-minX) + (maxY-minY)*(maxY-minY))\n",
    "    print(diagonal.shape)\n",
    "    res = []\n",
    "    for batch, m, d in zip(sample_batch, minimum, diagonal):\n",
    "        res.append(torch.sub(batch, m)/d)\n",
    "    print(torch.stack(res).shape)\n",
    "    print(maximum)\n",
    "    print(minimum)\n",
    "    print(sample_batch)#[:,1].max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2ce311-ea0b-4e3e-a6d9-608b25b096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, train_dataset, train_loader, loss_func, opt, batch_size, epochs = 10):\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        for i_batch, sample_batch in enumerate(train_loader):\n",
    "            sample_batch = torch.concat(sample_batch, axis = 1)\n",
    "            for i in range(2):\n",
    "                inp = sample_batch[:,i*50:(i+1)*50,:]\n",
    "                maximum = inp.max(axis = 1).values+1\n",
    "                minimum = inp.min(axis = 1).values-1\n",
    "                # normalization\n",
    "                inp = normalize(inp, maximum, minimum, how = 'normalize')\n",
    "                \n",
    "                out = sample_batch[:,i*50+1:(i+1)*50+1,:]\n",
    "                out = out.float()\n",
    "                \n",
    "                # init hidden states\n",
    "                h = model.init_hidden(inp.shape[0])\n",
    "                \n",
    "                # prediction\n",
    "                preds, _ = model(inp, h)\n",
    "                preds = normalize(preds, maximum, minimum, how = 'reverse')\n",
    "                loss = loss_func(preds, out)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        print('epoch {} trian loss: {}'.format(epoch, total_loss / len(train_dataset)))\n",
    "        train_losses.append(total_loss / (len(train_dataset)*2))\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d868104-278b-475c-b28a-1176b46a239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, val_loader, loss_func, opt):\n",
    "    val_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(val_loader):\n",
    "        inp, out = sample_batch\n",
    "        out = out.float()\n",
    "        preds = model(inp)\n",
    "        loss = loss_func(preds, out) # MSE\n",
    "        #loss = torch.sqrt(loss_func(preds, out)) # RMSE\n",
    "\n",
    "        val_loss += loss.item()\n",
    "    print('val loss: {}'.format(val_loss / len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8d1e9d-3dde-411c-a35f-2f3760c6527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_city(city, batch_size, epochs, model):\n",
    "    # data loader\n",
    "    train_dataset, val_dataset, train_loader, val_loader = get_data_loader(city = city, batch_size = batch_size)\n",
    "    \n",
    "    # model, optimizer, loss\n",
    "    model_encdoc = model\n",
    "    opt = optim.Adam(model_encdoc.parameters(), lr=1e-3)\n",
    "    loss_func = nn.MSELoss()\n",
    "    \n",
    "    # train\n",
    "    train_losses = train_epochs(model_encdoc, train_dataset, train_loader, loss_func, opt, batch_size, epochs = epochs)\n",
    "    \n",
    "    # evaluate\n",
    "    # val_loss(model_encdoc, val_loader, loss_func, opt)\n",
    "    return model_encdoc, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eaa45b-3002-4f32-82a8-b0d1ed88d8be",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee33333-73a8-4e13-aa28-14fae7b6c6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 trian loss: 1.1438868258522346\n",
      "epoch 1 trian loss: 0.20265075298490134\n",
      "epoch 2 trian loss: 0.12056106716726793\n",
      "epoch 3 trian loss: 0.08615755070984142\n",
      "epoch 4 trian loss: 0.06482210422980297\n",
      "epoch 5 trian loss: 0.048769403899912495\n",
      "epoch 6 trian loss: 0.035096621729405836\n",
      "epoch 7 trian loss: 0.026958336755910327\n",
      "epoch 8 trian loss: 0.021673208968125312\n",
      "epoch 9 trian loss: 0.0174283448011237\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM()\n",
    "opt = optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "model_austin, train_losses = train_city('austin', batch_size = 128, epochs = 10, model = lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "771bef46-2f75-411e-a818-5beb83c307ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 trian loss: 0.6996646434426178\n",
      "epoch 1 trian loss: 0.10192262489377087\n",
      "epoch 2 trian loss: 0.05895808383535359\n",
      "epoch 3 trian loss: 0.039356976606680326\n",
      "epoch 4 trian loss: 0.027435437272739862\n",
      "epoch 5 trian loss: 0.019393314343719038\n",
      "epoch 6 trian loss: 0.013297961922568956\n",
      "epoch 7 trian loss: 0.009181177949784063\n",
      "epoch 8 trian loss: 0.007187541646010136\n",
      "epoch 9 trian loss: 0.004679342127201645\n"
     ]
    }
   ],
   "source": [
    "# miami\n",
    "model = LSTM()\n",
    "model_miami, train_losses = train_city('miami', batch_size = 128, epochs = 10, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b9010a1a-1cbd-4a7c-95c0-6232b4b06ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 trian loss: 0.8785172605567916\n",
      "epoch 1 trian loss: 0.15234190443779658\n",
      "epoch 2 trian loss: 0.08934505988506204\n",
      "epoch 3 trian loss: 0.06200308441605845\n",
      "epoch 4 trian loss: 0.04657862538648928\n",
      "epoch 5 trian loss: 0.035361664588308604\n",
      "epoch 6 trian loss: 0.025396661269087063\n",
      "epoch 7 trian loss: 0.018552193991398395\n",
      "epoch 8 trian loss: 0.014353059064109198\n",
      "epoch 9 trian loss: 0.011146067723385446\n"
     ]
    }
   ],
   "source": [
    "# pittsburgh\n",
    "model = LSTM()\n",
    "model_pittsburgh, train_losses = train_city('pittsburgh', batch_size = 128, epochs = 10, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "3e20594b-5b05-4a1e-bd23-1943ac7ceda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 trian loss: 2.6705615339177804\n",
      "epoch 1 trian loss: 0.8198084842934534\n",
      "epoch 2 trian loss: 0.40010392890050583\n",
      "epoch 3 trian loss: 0.27516686282777825\n",
      "epoch 4 trian loss: 0.21209165100571764\n",
      "epoch 5 trian loss: 0.169051072876276\n",
      "epoch 6 trian loss: 0.13831314451852394\n",
      "epoch 7 trian loss: 0.11532150675601288\n",
      "epoch 8 trian loss: 0.09674786858546958\n",
      "epoch 9 trian loss: 0.08019321830372096\n"
     ]
    }
   ],
   "source": [
    "# dearborn\n",
    "model = LSTM()\n",
    "model_dearborn, train_losses = train_city('dearborn', batch_size = 128, epochs = 10, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "699c833f-e158-4ea7-bf55-f3b9f8491daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 trian loss: 1.7021853595902592\n",
      "epoch 1 trian loss: 0.4399799744843881\n",
      "epoch 2 trian loss: 0.20162403778040602\n",
      "epoch 3 trian loss: 0.13777359011753085\n",
      "epoch 4 trian loss: 0.10513982591280756\n",
      "epoch 5 trian loss: 0.08358460539704436\n",
      "epoch 6 trian loss: 0.06893526424061168\n",
      "epoch 7 trian loss: 0.05818317116186798\n",
      "epoch 8 trian loss: 0.049258689919273894\n",
      "epoch 9 trian loss: 0.04050426702677231\n"
     ]
    }
   ],
   "source": [
    "# washington_dc\n",
    "model = LSTM()\n",
    "model_washington_dc, train_losses = train_city('washington-dc', batch_size = 128, epochs = 10, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "a750f169-ec63-4add-a36b-680209e58b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 trian loss: 3.083900693459149\n",
      "epoch 1 trian loss: 1.183693142112242\n",
      "epoch 2 trian loss: 0.6522291436406152\n",
      "epoch 3 trian loss: 0.41429494996186195\n",
      "epoch 4 trian loss: 0.3063684842107294\n",
      "epoch 5 trian loss: 0.2540908683032369\n",
      "epoch 6 trian loss: 0.22171622141885003\n",
      "epoch 7 trian loss: 0.19749431832817022\n",
      "epoch 8 trian loss: 0.1772657184425844\n",
      "epoch 9 trian loss: 0.16015046551587483\n"
     ]
    }
   ],
   "source": [
    "# palo_alto\n",
    "model = LSTM()\n",
    "model_palo_alto, train_losses = train_city('palo-alto', batch_size = 128, epochs = 10, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af437a3a-2ca4-448b-97d9-7ee9c0218705",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1cb0027-205a-46ca-ad37-7e5bb6a99dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_miami' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m cities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maustin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiami\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpittsburgh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdearborn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwashington-dc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpalo-alto\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m models \u001b[38;5;241m=\u001b[39m [model_austin, \u001b[43mmodel_miami\u001b[49m, model_pittsburgh, model_dearborn, model_washington_dc, model_palo_alto]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_miami' is not defined"
     ]
    }
   ],
   "source": [
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "models = [model_austin, model_miami, model_pittsburgh, model_dearborn, model_washington_dc, model_palo_alto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc8904c-b290-4d3e-a5a3-44a05af3ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inp):\n",
    "    # init hidden states\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    preds = []\n",
    "    p_t = inp\n",
    "    maximum = p_t.max(axis = 1).values+1\n",
    "    minimum = p_t.min(axis = 1).values-1\n",
    "    p_t = normalize(p_t, maximum, minimum, how = 'normalize')\n",
    "    for i in range(60):\n",
    "        p_t, h = model(inp, h)\n",
    "        preds.append(normalize(p_t[:,49:50,:], maximum, minimum, how = 'reverse'))\n",
    "    preds = torch.concat(preds, axis = 1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8db468-cc50-4653-b31a-9209056c25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(city, model):\n",
    "    test_dataset = get_city_trajectories(city = city, split = 'test')[0]\n",
    "    test_dataset = torch.from_numpy(test_dataset)\n",
    "    pred = predict(model, test_dataset).reshape(-1, 120)\n",
    "    return pd.DataFrame(pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00631b6c-4f48-43c2-a82c-f5b2804e3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6325, 50, 2])\n"
     ]
    }
   ],
   "source": [
    "test_dataset = get_city_trajectories(city = 'austin', split = 'test')[0]\n",
    "test_dataset = torch.from_numpy(test_dataset)#[:100,:,:]\n",
    "print(test_dataset.shape)\n",
    "predict(model_austin, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "9461fe18-3aa0-4fe1-b170-4536b42b10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['ID'] + ['v'+str(i) for i in range(120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "7ffd5f7c-90ec-4cd5-980c-81597d2731da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(cities, models):\n",
    "    out = predict_test(cities[0], models[0]).reset_index()\n",
    "    out.columns = columns\n",
    "    out['ID'] = out['ID'].astype(str) + '_' + cities[0]\n",
    "    \n",
    "    for city, model in zip(cities[1:], models[1:]):\n",
    "        temp = predict_test(city, model).reset_index()\n",
    "        temp.columns = columns\n",
    "        temp['ID'] = temp['ID'].astype(str) + '_' + city\n",
    "        out = pd.concat([out, temp])\n",
    "    \n",
    "    return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "5a4b23dd-53bd-42ba-b09d-1e651be8a618",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [526]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_output \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [525]\u001b[0m, in \u001b[0;36mpredict_all\u001b[1;34m(cities, models)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_all\u001b[39m(cities, models):\n\u001b[1;32m----> 2\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      3\u001b[0m     out\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m columns\n\u001b[0;32m      4\u001b[0m     out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m cities[\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[1;32mIn [523]\u001b[0m, in \u001b[0;36mpredict_test\u001b[1;34m(city, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m get_city_trajectories(city \u001b[38;5;241m=\u001b[39m city, split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_dataset)\n\u001b[1;32m----> 4\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m120\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Input \u001b[1;32mIn [522]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, inp)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[0;32m     10\u001b[0m     p_t, h \u001b[38;5;241m=\u001b[39m model(inp, h)\n\u001b[1;32m---> 11\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m49\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreverse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat(preds, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\n",
      "Input \u001b[1;32mIn [400]\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(inp, maximum, minimum, how)\u001b[0m\n\u001b[0;32m     11\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, m, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inp, minimum, diagonal):\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(res)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_output = predict_all(cities, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756b051-2523-405f-8740-efd0a0fe6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd7baf-3157-4d67-8615-4f56baee7788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb2c407-515c-43e1-b38e-02cc183a6a01",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "f89a240b-e905-4a87-a53c-5b72f9d0ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, train_loader, val_loader = get_data_loader(city = 'miami', batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "eef3ebdb-cfd8-454e-83bd-402312b2e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3352, 1.4284],\n",
      "         [0.3358, 1.4126],\n",
      "         [0.3365, 1.3945],\n",
      "         [0.3372, 1.3742],\n",
      "         [0.3380, 1.3510],\n",
      "         [0.3389, 1.3268],\n",
      "         [0.3397, 1.3018],\n",
      "         [0.3404, 1.2758],\n",
      "         [0.3412, 1.2509],\n",
      "         [0.3419, 1.2274],\n",
      "         [0.3426, 1.2059],\n",
      "         [0.3432, 1.1846],\n",
      "         [0.3438, 1.1632],\n",
      "         [0.3443, 1.1417],\n",
      "         [0.3449, 1.1195],\n",
      "         [0.3455, 1.0973],\n",
      "         [0.3461, 1.0749],\n",
      "         [0.3468, 1.0521],\n",
      "         [0.3476, 1.0289],\n",
      "         [0.3484, 1.0051],\n",
      "         [0.3493, 0.9821],\n",
      "         [0.3502, 0.9589],\n",
      "         [0.3512, 0.9354],\n",
      "         [0.3521, 0.9130],\n",
      "         [0.3531, 0.8906],\n",
      "         [0.3540, 0.8683],\n",
      "         [0.3550, 0.8471],\n",
      "         [0.3559, 0.8259],\n",
      "         [0.3568, 0.8045],\n",
      "         [0.3575, 0.7832],\n",
      "         [0.3582, 0.7618],\n",
      "         [0.3589, 0.7397],\n",
      "         [0.3594, 0.7175],\n",
      "         [0.3599, 0.6958],\n",
      "         [0.3602, 0.6754],\n",
      "         [0.3606, 0.6555],\n",
      "         [0.3610, 0.6357],\n",
      "         [0.3614, 0.6158],\n",
      "         [0.3619, 0.5957],\n",
      "         [0.3624, 0.5751],\n",
      "         [0.3630, 0.5540],\n",
      "         [0.3637, 0.5324],\n",
      "         [0.3644, 0.5102],\n",
      "         [0.3652, 0.4873],\n",
      "         [0.3661, 0.4638],\n",
      "         [0.3672, 0.4395],\n",
      "         [0.3683, 0.4145],\n",
      "         [0.3695, 0.3887],\n",
      "         [0.3707, 0.3623],\n",
      "         [0.3719, 0.3352]],\n",
      "\n",
      "        [[0.2963, 0.6959],\n",
      "         [0.2964, 0.6958],\n",
      "         [0.2964, 0.6956],\n",
      "         [0.2965, 0.6955],\n",
      "         [0.2965, 0.6953],\n",
      "         [0.2966, 0.6950],\n",
      "         [0.2967, 0.6947],\n",
      "         [0.2968, 0.6945],\n",
      "         [0.2969, 0.6942],\n",
      "         [0.2971, 0.6935],\n",
      "         [0.2976, 0.6922],\n",
      "         [0.2983, 0.6902],\n",
      "         [0.2992, 0.6874],\n",
      "         [0.3005, 0.6837],\n",
      "         [0.3020, 0.6792],\n",
      "         [0.3036, 0.6740],\n",
      "         [0.3056, 0.6679],\n",
      "         [0.3075, 0.6618],\n",
      "         [0.3093, 0.6558],\n",
      "         [0.3111, 0.6497],\n",
      "         [0.3129, 0.6436],\n",
      "         [0.3147, 0.6374],\n",
      "         [0.3164, 0.6314],\n",
      "         [0.3181, 0.6254],\n",
      "         [0.3197, 0.6195],\n",
      "         [0.3213, 0.6135],\n",
      "         [0.3232, 0.6070],\n",
      "         [0.3253, 0.5997],\n",
      "         [0.3277, 0.5917],\n",
      "         [0.3303, 0.5828],\n",
      "         [0.3332, 0.5730],\n",
      "         [0.3364, 0.5622],\n",
      "         [0.3398, 0.5507],\n",
      "         [0.3433, 0.5386],\n",
      "         [0.3471, 0.5259],\n",
      "         [0.3507, 0.5135],\n",
      "         [0.3544, 0.5007],\n",
      "         [0.3582, 0.4873],\n",
      "         [0.3620, 0.4737],\n",
      "         [0.3658, 0.4599],\n",
      "         [0.3697, 0.4458],\n",
      "         [0.3737, 0.4313],\n",
      "         [0.3779, 0.4162],\n",
      "         [0.3822, 0.4007],\n",
      "         [0.3868, 0.3846],\n",
      "         [0.3914, 0.3680],\n",
      "         [0.3960, 0.3509],\n",
      "         [0.4008, 0.3333],\n",
      "         [0.4057, 0.3151],\n",
      "         [0.4108, 0.2963]],\n",
      "\n",
      "        [[0.2710, 0.2714],\n",
      "         [0.2709, 0.2714],\n",
      "         [0.2709, 0.2714],\n",
      "         [0.2708, 0.2714],\n",
      "         [0.2708, 0.2713],\n",
      "         [0.2707, 0.2713],\n",
      "         [0.2707, 0.2712],\n",
      "         [0.2707, 0.2712],\n",
      "         [0.2707, 0.2712],\n",
      "         [0.2708, 0.2711],\n",
      "         [0.2708, 0.2710],\n",
      "         [0.2709, 0.2710],\n",
      "         [0.2708, 0.2709],\n",
      "         [0.2708, 0.2709],\n",
      "         [0.2708, 0.2708],\n",
      "         [0.2711, 0.2708],\n",
      "         [0.2718, 0.2707],\n",
      "         [0.2730, 0.2707],\n",
      "         [0.2748, 0.2707],\n",
      "         [0.2773, 0.2707],\n",
      "         [0.2804, 0.2708],\n",
      "         [0.2841, 0.2709],\n",
      "         [0.2882, 0.2710],\n",
      "         [0.2927, 0.2711],\n",
      "         [0.2973, 0.2713],\n",
      "         [0.3020, 0.2716],\n",
      "         [0.3066, 0.2719],\n",
      "         [0.3111, 0.2721],\n",
      "         [0.3154, 0.2724],\n",
      "         [0.3194, 0.2727],\n",
      "         [0.3233, 0.2730],\n",
      "         [0.3272, 0.2734],\n",
      "         [0.3314, 0.2741],\n",
      "         [0.3359, 0.2749],\n",
      "         [0.3408, 0.2760],\n",
      "         [0.3463, 0.2776],\n",
      "         [0.3524, 0.2795],\n",
      "         [0.3589, 0.2818],\n",
      "         [0.3657, 0.2845],\n",
      "         [0.3726, 0.2875],\n",
      "         [0.3797, 0.2909],\n",
      "         [0.3866, 0.2945],\n",
      "         [0.3934, 0.2984],\n",
      "         [0.4000, 0.3025],\n",
      "         [0.4064, 0.3066],\n",
      "         [0.4126, 0.3108],\n",
      "         [0.4186, 0.3150],\n",
      "         [0.4245, 0.3195],\n",
      "         [0.4304, 0.3241],\n",
      "         [0.4364, 0.3289]],\n",
      "\n",
      "        [[0.3404, 0.9834],\n",
      "         [0.3407, 0.9721],\n",
      "         [0.3412, 0.9581],\n",
      "         [0.3419, 0.9415],\n",
      "         [0.3427, 0.9225],\n",
      "         [0.3437, 0.9014],\n",
      "         [0.3447, 0.8787],\n",
      "         [0.3459, 0.8548],\n",
      "         [0.3471, 0.8305],\n",
      "         [0.3483, 0.8065],\n",
      "         [0.3495, 0.7836],\n",
      "         [0.3506, 0.7629],\n",
      "         [0.3517, 0.7427],\n",
      "         [0.3528, 0.7231],\n",
      "         [0.3537, 0.7035],\n",
      "         [0.3546, 0.6844],\n",
      "         [0.3553, 0.6657],\n",
      "         [0.3560, 0.6475],\n",
      "         [0.3566, 0.6298],\n",
      "         [0.3571, 0.6125],\n",
      "         [0.3576, 0.5958],\n",
      "         [0.3581, 0.5795],\n",
      "         [0.3584, 0.5637],\n",
      "         [0.3588, 0.5487],\n",
      "         [0.3591, 0.5341],\n",
      "         [0.3595, 0.5201],\n",
      "         [0.3599, 0.5068],\n",
      "         [0.3602, 0.4941],\n",
      "         [0.3606, 0.4822],\n",
      "         [0.3611, 0.4709],\n",
      "         [0.3614, 0.4604],\n",
      "         [0.3618, 0.4503],\n",
      "         [0.3622, 0.4407],\n",
      "         [0.3626, 0.4314],\n",
      "         [0.3629, 0.4223],\n",
      "         [0.3634, 0.4136],\n",
      "         [0.3637, 0.4051],\n",
      "         [0.3640, 0.3970],\n",
      "         [0.3644, 0.3893],\n",
      "         [0.3647, 0.3821],\n",
      "         [0.3649, 0.3755],\n",
      "         [0.3652, 0.3694],\n",
      "         [0.3654, 0.3639],\n",
      "         [0.3656, 0.3591],\n",
      "         [0.3659, 0.3548],\n",
      "         [0.3660, 0.3510],\n",
      "         [0.3662, 0.3478],\n",
      "         [0.3664, 0.3449],\n",
      "         [0.3666, 0.3425],\n",
      "         [0.3667, 0.3404]],\n",
      "\n",
      "        [[0.4894, 0.2236],\n",
      "         [0.4846, 0.2234],\n",
      "         [0.4785, 0.2231],\n",
      "         [0.4710, 0.2228],\n",
      "         [0.4622, 0.2223],\n",
      "         [0.4523, 0.2218],\n",
      "         [0.4415, 0.2213],\n",
      "         [0.4302, 0.2207],\n",
      "         [0.4185, 0.2201],\n",
      "         [0.4068, 0.2195],\n",
      "         [0.3953, 0.2190],\n",
      "         [0.3846, 0.2185],\n",
      "         [0.3739, 0.2181],\n",
      "         [0.3634, 0.2179],\n",
      "         [0.3532, 0.2177],\n",
      "         [0.3434, 0.2178],\n",
      "         [0.3339, 0.2179],\n",
      "         [0.3249, 0.2182],\n",
      "         [0.3163, 0.2183],\n",
      "         [0.3080, 0.2185],\n",
      "         [0.3002, 0.2187],\n",
      "         [0.2930, 0.2189],\n",
      "         [0.2865, 0.2193],\n",
      "         [0.2811, 0.2197],\n",
      "         [0.2763, 0.2202],\n",
      "         [0.2719, 0.2207],\n",
      "         [0.2680, 0.2212],\n",
      "         [0.2645, 0.2218],\n",
      "         [0.2611, 0.2223],\n",
      "         [0.2579, 0.2228],\n",
      "         [0.2549, 0.2233],\n",
      "         [0.2520, 0.2237],\n",
      "         [0.2491, 0.2241],\n",
      "         [0.2463, 0.2243],\n",
      "         [0.2437, 0.2246],\n",
      "         [0.2412, 0.2246],\n",
      "         [0.2388, 0.2246],\n",
      "         [0.2364, 0.2244],\n",
      "         [0.2344, 0.2243],\n",
      "         [0.2325, 0.2241],\n",
      "         [0.2310, 0.2240],\n",
      "         [0.2297, 0.2239],\n",
      "         [0.2283, 0.2239],\n",
      "         [0.2271, 0.2240],\n",
      "         [0.2260, 0.2241],\n",
      "         [0.2248, 0.2242],\n",
      "         [0.2233, 0.2244],\n",
      "         [0.2216, 0.2246],\n",
      "         [0.2198, 0.2248],\n",
      "         [0.2177, 0.2249]],\n",
      "\n",
      "        [[0.4061, 0.3489],\n",
      "         [0.4051, 0.3501],\n",
      "         [0.4038, 0.3516],\n",
      "         [0.4023, 0.3533],\n",
      "         [0.4007, 0.3551],\n",
      "         [0.3989, 0.3571],\n",
      "         [0.3971, 0.3593],\n",
      "         [0.3950, 0.3616],\n",
      "         [0.3929, 0.3635],\n",
      "         [0.3908, 0.3652],\n",
      "         [0.3888, 0.3666],\n",
      "         [0.3866, 0.3677],\n",
      "         [0.3843, 0.3685],\n",
      "         [0.3821, 0.3692],\n",
      "         [0.3798, 0.3697],\n",
      "         [0.3775, 0.3701],\n",
      "         [0.3752, 0.3700],\n",
      "         [0.3728, 0.3696],\n",
      "         [0.3701, 0.3689],\n",
      "         [0.3677, 0.3682],\n",
      "         [0.3651, 0.3673],\n",
      "         [0.3627, 0.3661],\n",
      "         [0.3601, 0.3650],\n",
      "         [0.3576, 0.3639],\n",
      "         [0.3552, 0.3624],\n",
      "         [0.3526, 0.3611],\n",
      "         [0.3500, 0.3595],\n",
      "         [0.3475, 0.3577],\n",
      "         [0.3449, 0.3560],\n",
      "         [0.3424, 0.3541],\n",
      "         [0.3401, 0.3521],\n",
      "         [0.3379, 0.3500],\n",
      "         [0.3357, 0.3481],\n",
      "         [0.3335, 0.3461],\n",
      "         [0.3313, 0.3441],\n",
      "         [0.3289, 0.3420],\n",
      "         [0.3265, 0.3396],\n",
      "         [0.3244, 0.3371],\n",
      "         [0.3223, 0.3346],\n",
      "         [0.3203, 0.3318],\n",
      "         [0.3182, 0.3292],\n",
      "         [0.3163, 0.3264],\n",
      "         [0.3143, 0.3234],\n",
      "         [0.3122, 0.3206],\n",
      "         [0.3102, 0.3175],\n",
      "         [0.3083, 0.3143],\n",
      "         [0.3064, 0.3112],\n",
      "         [0.3045, 0.3078],\n",
      "         [0.3027, 0.3044],\n",
      "         [0.3010, 0.3010]],\n",
      "\n",
      "        [[0.4088, 0.7810],\n",
      "         [0.4074, 0.7753],\n",
      "         [0.4069, 0.7679],\n",
      "         [0.4021, 0.7588],\n",
      "         [0.3961, 0.7476],\n",
      "         [0.3923, 0.7350],\n",
      "         [0.3893, 0.7211],\n",
      "         [0.3869, 0.7058],\n",
      "         [0.3866, 0.6896],\n",
      "         [0.3857, 0.6730],\n",
      "         [0.3847, 0.6565],\n",
      "         [0.3831, 0.6405],\n",
      "         [0.3807, 0.6250],\n",
      "         [0.3772, 0.6098],\n",
      "         [0.3720, 0.5944],\n",
      "         [0.3661, 0.5798],\n",
      "         [0.3608, 0.5660],\n",
      "         [0.3571, 0.5520],\n",
      "         [0.3537, 0.5384],\n",
      "         [0.3512, 0.5251],\n",
      "         [0.3467, 0.5124],\n",
      "         [0.3390, 0.5002],\n",
      "         [0.3351, 0.4886],\n",
      "         [0.3338, 0.4781],\n",
      "         [0.3319, 0.4681],\n",
      "         [0.3309, 0.4589],\n",
      "         [0.3303, 0.4508],\n",
      "         [0.3293, 0.4425],\n",
      "         [0.3278, 0.4343],\n",
      "         [0.3263, 0.4256],\n",
      "         [0.3247, 0.4178],\n",
      "         [0.3232, 0.4110],\n",
      "         [0.3218, 0.4037],\n",
      "         [0.3192, 0.3970],\n",
      "         [0.3178, 0.3915],\n",
      "         [0.3175, 0.3862],\n",
      "         [0.3168, 0.3808],\n",
      "         [0.3162, 0.3750],\n",
      "         [0.3135, 0.3694],\n",
      "         [0.3112, 0.3638],\n",
      "         [0.3080, 0.3584],\n",
      "         [0.3052, 0.3525],\n",
      "         [0.3031, 0.3463],\n",
      "         [0.3019, 0.3401],\n",
      "         [0.3010, 0.3336],\n",
      "         [0.3021, 0.3260],\n",
      "         [0.3022, 0.3182],\n",
      "         [0.3008, 0.3100],\n",
      "         [0.2983, 0.3034],\n",
      "         [0.3008, 0.2983]],\n",
      "\n",
      "        [[0.3746, 0.3325],\n",
      "         [0.3719, 0.3440],\n",
      "         [0.3689, 0.3606],\n",
      "         [0.3650, 0.3832],\n",
      "         [0.3618, 0.4118],\n",
      "         [0.3585, 0.4459],\n",
      "         [0.3562, 0.4856],\n",
      "         [0.3539, 0.5300],\n",
      "         [0.3516, 0.5784],\n",
      "         [0.3495, 0.6293],\n",
      "         [0.3475, 0.6811],\n",
      "         [0.3463, 0.7333],\n",
      "         [0.3457, 0.7839],\n",
      "         [0.3469, 0.8325],\n",
      "         [0.3470, 0.8813],\n",
      "         [0.3473, 0.9302],\n",
      "         [0.3475, 0.9789],\n",
      "         [0.3478, 1.0261],\n",
      "         [0.3485, 1.0726],\n",
      "         [0.3489, 1.1182],\n",
      "         [0.3502, 1.1629],\n",
      "         [0.3513, 1.2075],\n",
      "         [0.3531, 1.2514],\n",
      "         [0.3544, 1.2943],\n",
      "         [0.3562, 1.3366],\n",
      "         [0.3568, 1.3781],\n",
      "         [0.3569, 1.4189],\n",
      "         [0.3568, 1.4588],\n",
      "         [0.3569, 1.4982],\n",
      "         [0.3574, 1.5427],\n",
      "         [0.3572, 1.5840],\n",
      "         [0.3569, 1.6225],\n",
      "         [0.3549, 1.6581],\n",
      "         [0.3529, 1.6911],\n",
      "         [0.3510, 1.7216],\n",
      "         [0.3498, 1.7498],\n",
      "         [0.3479, 1.7764],\n",
      "         [0.3457, 1.8016],\n",
      "         [0.3443, 1.8224],\n",
      "         [0.3422, 1.8447],\n",
      "         [0.3401, 1.8684],\n",
      "         [0.3383, 1.8932],\n",
      "         [0.3367, 1.9198],\n",
      "         [0.3353, 1.9483],\n",
      "         [0.3342, 1.9788],\n",
      "         [0.3339, 2.0110],\n",
      "         [0.3339, 2.0453],\n",
      "         [0.3338, 2.0818],\n",
      "         [0.3331, 2.1122],\n",
      "         [0.3325, 2.1412]],\n",
      "\n",
      "        [[0.3438, 0.8006],\n",
      "         [0.3444, 0.7849],\n",
      "         [0.3451, 0.7666],\n",
      "         [0.3460, 0.7460],\n",
      "         [0.3469, 0.7234],\n",
      "         [0.3478, 0.6993],\n",
      "         [0.3487, 0.6744],\n",
      "         [0.3496, 0.6494],\n",
      "         [0.3506, 0.6255],\n",
      "         [0.3515, 0.6037],\n",
      "         [0.3523, 0.5850],\n",
      "         [0.3532, 0.5672],\n",
      "         [0.3541, 0.5502],\n",
      "         [0.3550, 0.5342],\n",
      "         [0.3559, 0.5190],\n",
      "         [0.3568, 0.5046],\n",
      "         [0.3577, 0.4910],\n",
      "         [0.3586, 0.4783],\n",
      "         [0.3595, 0.4665],\n",
      "         [0.3603, 0.4556],\n",
      "         [0.3611, 0.4455],\n",
      "         [0.3617, 0.4363],\n",
      "         [0.3621, 0.4278],\n",
      "         [0.3623, 0.4202],\n",
      "         [0.3624, 0.4134],\n",
      "         [0.3625, 0.4076],\n",
      "         [0.3625, 0.4026],\n",
      "         [0.3625, 0.3980],\n",
      "         [0.3625, 0.3934],\n",
      "         [0.3626, 0.3888],\n",
      "         [0.3625, 0.3843],\n",
      "         [0.3625, 0.3799],\n",
      "         [0.3624, 0.3756],\n",
      "         [0.3622, 0.3711],\n",
      "         [0.3621, 0.3667],\n",
      "         [0.3619, 0.3625],\n",
      "         [0.3616, 0.3586],\n",
      "         [0.3615, 0.3550],\n",
      "         [0.3613, 0.3520],\n",
      "         [0.3611, 0.3499],\n",
      "         [0.3610, 0.3485],\n",
      "         [0.3610, 0.3477],\n",
      "         [0.3611, 0.3473],\n",
      "         [0.3613, 0.3468],\n",
      "         [0.3617, 0.3463],\n",
      "         [0.3621, 0.3458],\n",
      "         [0.3625, 0.3452],\n",
      "         [0.3628, 0.3446],\n",
      "         [0.3631, 0.3442],\n",
      "         [0.3633, 0.3438]],\n",
      "\n",
      "        [[0.3683, 0.3388],\n",
      "         [0.3680, 0.3557],\n",
      "         [0.3677, 0.3764],\n",
      "         [0.3672, 0.4005],\n",
      "         [0.3667, 0.4277],\n",
      "         [0.3661, 0.4576],\n",
      "         [0.3656, 0.4895],\n",
      "         [0.3651, 0.5227],\n",
      "         [0.3646, 0.5564],\n",
      "         [0.3642, 0.5893],\n",
      "         [0.3638, 0.6205],\n",
      "         [0.3634, 0.6512],\n",
      "         [0.3629, 0.6815],\n",
      "         [0.3624, 0.7120],\n",
      "         [0.3619, 0.7424],\n",
      "         [0.3614, 0.7728],\n",
      "         [0.3608, 0.8030],\n",
      "         [0.3601, 0.8333],\n",
      "         [0.3594, 0.8641],\n",
      "         [0.3587, 0.8951],\n",
      "         [0.3579, 0.9261],\n",
      "         [0.3571, 0.9570],\n",
      "         [0.3563, 0.9880],\n",
      "         [0.3556, 1.0190],\n",
      "         [0.3549, 1.0500],\n",
      "         [0.3544, 1.0810],\n",
      "         [0.3538, 1.1119],\n",
      "         [0.3533, 1.1429],\n",
      "         [0.3527, 1.1738],\n",
      "         [0.3521, 1.2048],\n",
      "         [0.3514, 1.2358],\n",
      "         [0.3507, 1.2669],\n",
      "         [0.3501, 1.2979],\n",
      "         [0.3494, 1.3284],\n",
      "         [0.3488, 1.3588],\n",
      "         [0.3481, 1.3890],\n",
      "         [0.3474, 1.4194],\n",
      "         [0.3468, 1.4496],\n",
      "         [0.3461, 1.4797],\n",
      "         [0.3455, 1.5098],\n",
      "         [0.3450, 1.5400],\n",
      "         [0.3445, 1.5702],\n",
      "         [0.3440, 1.6007],\n",
      "         [0.3435, 1.6312],\n",
      "         [0.3431, 1.6620],\n",
      "         [0.3425, 1.6929],\n",
      "         [0.3418, 1.7238],\n",
      "         [0.3409, 1.7549],\n",
      "         [0.3399, 1.7858],\n",
      "         [0.3388, 1.8166]]])\n",
      "torch.Size([10, 60, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch < 5: continue\n",
    "    inp, out = sample_batch\n",
    "    maximum = inp.max(axis = 1).values+10\n",
    "    minimum = inp.min(axis = 1).values-10\n",
    "    inp = normalize(inp, maximum, minimum, how = 'normalize')\n",
    "    print(inp)\n",
    "\n",
    "    pred = predict(model_austin, inp).detach()\n",
    "    show_sample_batch([inp, inp])\n",
    "    #show_sample_batch([inp, pred])\n",
    "    print(pred.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e6037-2e37-4545-b7e7-2a1788aa986e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0018fd-f805-45f2-94c5-7c4cbcb35a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
