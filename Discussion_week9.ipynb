{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d761fce4-085f-4673-b67e-3f61860d2fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e665d190-05c8-4c3c-a9e3-aab8b485d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import nn, optim\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7293d76e-364e-4ec0-ae0a-8bade9e770fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train/austin_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 66>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m city \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maustin\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     65\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 66\u001b[0m inputs, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mget_city_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maustin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mget_city_trajectories\u001b[1;34m(city, split, normalized)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     16\u001b[0m     f_in \u001b[38;5;241m=\u001b[39m ROOT_PATH \u001b[38;5;241m+\u001b[39m split \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m city \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[0;32m     19\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(inputs)[:\u001b[38;5;28mint\u001b[39m(n \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m)]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train/austin_inputs'"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.1)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.1)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.1):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.1):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'austin' \n",
    "split = 'train'\n",
    "inputs, outputs = get_city_trajectories(city='austin', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce02f041-4cc3-48cf-ae1b-b2d59612c9d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mshape, outputs\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97537bfc-15a4-4037-8165-c6eae38295ae",
   "metadata": {},
   "source": [
    "# Data Normalization and Standardization For Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8107e3f-24cf-4083-a440-10ee014d5797",
   "metadata": {},
   "source": [
    "## Why do we need to normalize time series?\n",
    "#### 1). Large input values can result in a model that learns large weight values. \n",
    "#### 2). Large target values result in large error gradient values causing weight values to change dramatically, making the learning process unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fac005-527b-492f-bc94-bb1020b71ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = np.mean(inputs, axis = (0,1), keepdims = True)\n",
    "global_std = np.std(np.sqrt(inputs[:, :, 0]**2 + inputs[:, :, 0]**2))\n",
    "standard_inputs = (inputs - global_mean)/global_std\n",
    "standard_targets = (outputs - global_mean)/global_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cec80c-fd0a-4b7a-9d21-f7b177a174ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6270.,  19766., 346886., 662378., 628304., 465532., 248990.,\n",
       "        149815.,  51938.,   2581.]),\n",
       " array([-2.13738842, -1.67110405, -1.20481967, -0.7385353 , -0.27225093,\n",
       "         0.19403344,  0.66031781,  1.12660219,  1.59288656,  2.05917093,\n",
       "         2.5254553 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASRklEQVR4nO3dcYxd5Xnn8e+vEFrUlpiEqRfZVgepVisXbRJigaOsVruhNQNUNa2aiGhV3KwV/xFSpWql1mn/QJtsJEcrNVvU1JVVXEyVllppI6wCcV2SKlppTTw0FAJOlikFMRbEU0ygXdREpM/+Ma+jy+x9Zy7Gvndsfz/S1ZzznPec550ruD+fe8+5k6pCkqRhfmDSE5AkrV6GhCSpy5CQJHUZEpKkLkNCktR18aQncKZdccUVNT09PelpSNI55ZFHHvmnqppaWj/vQmJ6eprZ2dlJT0OSzilJnh1W9+0mSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS13l3x7XODdO77p9Y72d23zyx3tK5xjMJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSl3dc64Izqbu9vdNb5yLPJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1DVSSCRZk+TzSb6R5FiS9yR5W5LDSZ5qPy9vY5PkziRzSR5Lcs3Acba38U8l2T5Qf3eSx9s+dyZJqw/tIUkaj1HPJH4P+GJV/RTwDuAYsAt4qKo2Ag+1dYAbgY3tsRPYA4sv+MAdwHXAtcAdAy/6e4APD+w30+q9HpKkMVgxJJK8FfiPwF0AVfXdqvo2sA3Y34btB25py9uAe2rREWBNkiuBG4DDVXWyql4CDgMzbdtlVXWkqgq4Z8mxhvWQJI3BKGcSVwELwB8n+VqSP0ryw8Daqnq+jXkBWNuW1wHPDew/32rL1eeH1Fmmx+sk2ZlkNsnswsLCCL+SJGkUo4TExcA1wJ6qehfwf1nytk87A6gzP73RelTV3qraXFWbp6amzuY0JOmCMkpIzAPzVfVwW/88i6HxrfZWEe3nibb9OLBhYP/1rbZcff2QOsv0kCSNwYohUVUvAM8l+clWuh54EjgInLpCaTtwX1s+CNzWrnLaArzc3jI6BGxNcnn7wHorcKhteyXJlnZV021LjjWshyRpDEb9gr9fBT6X5BLgaeBDLAbMgSQ7gGeBD7SxDwA3AXPAq20sVXUyySeBo23cJ6rqZFv+CHA3cCnwYHsA7O70kCSNwUghUVWPApuHbLp+yNgCbu8cZx+wb0h9Frh6SP3FYT0kSePhHdeSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldI4VEkmeSPJ7k0SSzrfa2JIeTPNV+Xt7qSXJnkrkkjyW5ZuA429v4p5JsH6i/ux1/ru2b5XpIksbjjZxJ/OeqemdVbW7ru4CHqmoj8FBbB7gR2NgeO4E9sPiCD9wBXAdcC9wx8KK/B/jwwH4zK/SQJI3Bm3m7aRuwvy3vB24ZqN9Ti44Aa5JcCdwAHK6qk1X1EnAYmGnbLquqI1VVwD1LjjWshyRpDEYNiQL+OskjSXa22tqqer4tvwCsbcvrgOcG9p1vteXq80Pqy/V4nSQ7k8wmmV1YWBjxV5IkreTiEcf9h6o6nuTHgMNJvjG4saoqSZ356Y3Wo6r2AnsBNm/efFbnIUkXkpHOJKrqePt5AvgCi58pfKu9VUT7eaINPw5sGNh9fastV18/pM4yPSRJY7BiSCT54SQ/emoZ2Ap8HTgInLpCaTtwX1s+CNzWrnLaArzc3jI6BGxNcnn7wHorcKhteyXJlnZV021LjjWshyRpDEZ5u2kt8IV2VerFwJ9W1ReTHAUOJNkBPAt8oI1/ALgJmANeBT4EUFUnk3wSONrGfaKqTrbljwB3A5cCD7YHwO5OD0nSGKwYElX1NPCOIfUXgeuH1Au4vXOsfcC+IfVZ4OpRe0iSxsM7riVJXYaEJKnLkJAkdRkSkqQuQ0KS1DXqHdeS3qTpXfdPrPczu2+eWG+d2zyTkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHWNHBJJLkrytSR/1davSvJwkrkkf57kklb/wbY+17ZPDxzj463+zSQ3DNRnWm0uya6B+tAekqTxeCNnEh8Djg2sfxr4TFX9BPASsKPVdwAvtfpn2jiSbAJuBX4amAH+oAXPRcBngRuBTcAH29jlekiSxmCkkEiyHrgZ+KO2HuB9wOfbkP3ALW15W1unbb++jd8G3FtV36mqfwTmgGvbY66qnq6q7wL3AttW6CFJGoNRzyT+J/CbwL+19bcD366q19r6PLCuLa8DngNo219u479fX7JPr75cj9dJsjPJbJLZhYWFEX8lSdJKVgyJJD8HnKiqR8Ywn9NSVXuranNVbZ6ampr0dCTpvHHxCGPeC/x8kpuAHwIuA34PWJPk4vYv/fXA8Tb+OLABmE9yMfBW4MWB+imD+wyrv7hMD0nSGKx4JlFVH6+q9VU1zeIHz1+qqv8CfBn4pTZsO3BfWz7Y1mnbv1RV1eq3tqufrgI2Al8FjgIb25VMl7QeB9s+vR6SpDF4M/dJ/Bbw60nmWPz84K5Wvwt4e6v/OrALoKqeAA4ATwJfBG6vqu+1s4SPAodYvHrqQBu7XA9J0hiM8nbT91XV3wJ/25afZvHKpKVj/hV4f2f/TwGfGlJ/AHhgSH1oD0nSeHjHtSSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1vaGv5dD5Z3rX/ZOegqRVzDMJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXSuGRJIfSvLVJH+f5Ikk/63Vr0rycJK5JH+e5JJW/8G2Pte2Tw8c6+Ot/s0kNwzUZ1ptLsmugfrQHpKk8RjlTOI7wPuq6h3AO4GZJFuATwOfqaqfAF4CdrTxO4CXWv0zbRxJNgG3Aj8NzAB/kOSiJBcBnwVuBDYBH2xjWaaHJGkMVgyJWvQvbfUt7VHA+4DPt/p+4Ja2vK2t07ZfnyStfm9Vfaeq/hGYA65tj7mqerqqvgvcC2xr+/R6SJLGYKTPJNq/+B8FTgCHgX8Avl1Vr7Uh88C6trwOeA6gbX8ZePtgfck+vfrbl+mxdH47k8wmmV1YWBjlV5IkjWCkkKiq71XVO4H1LP7L/6fO6qzeoKraW1Wbq2rz1NTUpKcjSeeNN3R1U1V9G/gy8B5gTZJTf7RoPXC8LR8HNgC07W8FXhysL9mnV39xmR6SpDEY5eqmqSRr2vKlwM8Cx1gMi19qw7YD97Xlg22dtv1LVVWtfmu7+ukqYCPwVeAosLFdyXQJix9uH2z79HpIksZglD9feiWwv12F9APAgar6qyRPAvcm+e/A14C72vi7gD9JMgecZPFFn6p6IskB4EngNeD2qvoeQJKPAoeAi4B9VfVEO9ZvdXpIksZgxZCoqseAdw2pP83i5xNL6/8KvL9zrE8BnxpSfwB4YNQekqTx8I5rSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoa5bubJJ3jpnfdP5G+z+y+eSJ9deZ4JiFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrxZBIsiHJl5M8meSJJB9r9bclOZzkqfbz8lZPkjuTzCV5LMk1A8fa3sY/lWT7QP3dSR5v+9yZJMv1kCSNxyhnEq8Bv1FVm4AtwO1JNgG7gIeqaiPwUFsHuBHY2B47gT2w+IIP3AFcB1wL3DHwor8H+PDAfjOt3ushSRqDFUOiqp6vqr9ry/8MHAPWAduA/W3YfuCWtrwNuKcWHQHWJLkSuAE4XFUnq+ol4DAw07ZdVlVHqqqAe5Yca1gPSdIYvKHPJJJMA+8CHgbWVtXzbdMLwNq2vA54bmC3+VZbrj4/pM4yPZbOa2eS2SSzCwsLb+RXkiQtY+SQSPIjwF8Av1ZVrwxua2cAdYbn9jrL9aiqvVW1uao2T01Nnc1pSNIFZaSQSPIWFgPic1X1l638rfZWEe3niVY/DmwY2H19qy1XXz+kvlwPSdIYjHJ1U4C7gGNV9bsDmw4Cp65Q2g7cN1C/rV3ltAV4ub1ldAjYmuTy9oH1VuBQ2/ZKki2t121LjjWshyRpDEb586XvBX4ZeDzJo63228Bu4ECSHcCzwAfatgeAm4A54FXgQwBVdTLJJ4GjbdwnqupkW/4IcDdwKfBge7BMD0nSGKwYElX1v4B0Nl8/ZHwBt3eOtQ/YN6Q+C1w9pP7isB6SpPHwjmtJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6hrlu5sk6bRM77p/Yr2f2X3zxHqfTzyTkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1LViSCTZl+REkq8P1N6W5HCSp9rPy1s9Se5MMpfksSTXDOyzvY1/Ksn2gfq7kzze9rkzSZbrIUkan1HOJO4GZpbUdgEPVdVG4KG2DnAjsLE9dgJ7YPEFH7gDuA64Frhj4EV/D/Dhgf1mVughSRqTFUOiqr4CnFxS3gbsb8v7gVsG6vfUoiPAmiRXAjcAh6vqZFW9BBwGZtq2y6rqSFUVcM+SYw3rIUkak9P9TGJtVT3fll8A1rbldcBzA+PmW225+vyQ+nI9JElj8qY/uG5nAHUG5nLaPZLsTDKbZHZhYeFsTkWSLiinGxLfam8V0X6eaPXjwIaBcetbbbn6+iH15Xr8f6pqb1VtrqrNU1NTp/krSZKWOt2QOAicukJpO3DfQP22dpXTFuDl9pbRIWBrksvbB9ZbgUNt2ytJtrSrmm5bcqxhPSRJY7Liny9N8mfAfwKuSDLP4lVKu4EDSXYAzwIfaMMfAG4C5oBXgQ8BVNXJJJ8EjrZxn6iqUx+Gf4TFK6guBR5sD5bpIUkakxVDoqo+2Nl0/ZCxBdzeOc4+YN+Q+ixw9ZD6i8N6SJLGxzuuJUldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrxa/lkKRz0fSu+yfS95ndN0+k79nimYQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLO65XgUndGSpJK/FMQpLUZUhIkrpWfUgkmUnyzSRzSXZNej6SdCFZ1Z9JJLkI+Czws8A8cDTJwap68mz087MBSXq9VR0SwLXAXFU9DZDkXmAbcFZCQpLerPPtK8pXe0isA54bWJ8Hrls6KMlOYGdb/Zck3zyLc7oC+KezePxzgc/BIp8HnwNYJc9BPv2mD/Hjw4qrPSRGUlV7gb3j6JVktqo2j6PXauVzsMjnwecAzv/nYLV/cH0c2DCwvr7VJEljsNpD4iiwMclVSS4BbgUOTnhOknTBWNVvN1XVa0k+ChwCLgL2VdUTE57WWN7WWuV8Dhb5PPgcwHn+HKSqJj0HSdIqtdrfbpIkTZAhIUnqMiROQ5L/keQbSR5L8oUkayY9p3FL8v4kTyT5tyTn7eV/w/hVMZBkX5ITSb4+6blMSpINSb6c5Mn2/8LHJj2ns8GQOD2Hgaur6t8D/wf4+ITnMwlfB34R+MqkJzJOA18VcyOwCfhgkk2TndVE3A3MTHoSE/Ya8BtVtQnYAtx+Pv63YEichqr666p6ra0eYfH+jQtKVR2rqrN5Z/tq9f2viqmq7wKnvirmglJVXwFOTnoek1RVz1fV37XlfwaOsfgtEecVQ+LN+6/Ag5OehMZm2FfFnHcvDHpjkkwD7wIenuxMzrxVfZ/EJCX5G+DfDdn0O1V1XxvzOyyecn5unHMbl1GeA+lCl+RHgL8Afq2qXpn0fM40Q6Kjqn5mue1JfgX4OeD6Ok9vNlnpObhA+VUx+r4kb2ExID5XVX856fmcDb7ddBqSzAC/Cfx8Vb066florPyqGAGQJMBdwLGq+t1Jz+dsMSROz+8DPwocTvJokj+c9ITGLckvJJkH3gPcn+TQpOc0Du2ChVNfFXMMOLAKvipm7JL8GfC/gZ9MMp9kx6TnNAHvBX4ZeF97HXg0yU2TntSZ5tdySJK6PJOQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEld/w+FH9Uszs7uVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(standard_targets[:,:,1].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ef80d-d54f-49ce-ab48-58b77a85edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model(standard_inputs)\n",
    "# loss_fun(predictions, standard_targets)\n",
    "# inverse_preds = predictions*global_std + global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74509433-c436-4511-9d9e-b2355fc3dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min = np.min(inputs, axis = (0,1), keepdims = True)\n",
    "global_max = np.max(inputs, axis = (0,1), keepdims = True)\n",
    "normal_inputs = (inputs - global_min)/(global_max - global_min)\n",
    "normal_targets = (outputs - global_min)/(global_max - global_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f44f24-c3ed-4fc1-9530-e22a1da39fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_min = np.min(inputs, axis = (1), keepdims = True)\n",
    "traj_max = np.max(inputs, axis = (1), keepdims = True)\n",
    "normal_inputs = (inputs - traj_min)/(traj_max - traj_min)\n",
    "normal_targets = (outputs - traj_min)/(traj_max - traj_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea93b9a-4726-4312-b690-151d7c532924",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738a429c-eae6-404e-998a-f7514b2fea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = torch.from_numpy(standard_inputs[:32]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d1772-6d39-4b55-814e-4e514be8277a",
   "metadata": {},
   "source": [
    "## 1. Autoregressive Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39616a76-5188-40fa-b396-9f2ca8121aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "class LR(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(LR, self).__init__()\n",
    "        \"\"\"\n",
    "        the __init__() method that defines the layers and other components\n",
    "        \"\"\" \n",
    "        self.model = nn.Linear(input_dim, out_dim) # input_dim = input_length*2\n",
    "        \n",
    "    def forward(self, x, output_steps): \n",
    "        \"\"\"\n",
    "        the forward function is where computatioin gets done\n",
    "        \"\"\"\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(output_steps):\n",
    "            out = self.model(x)    \n",
    "            outputs.append(out)\n",
    "            x = torch.cat([x[:,2:],  out], dim = 1)\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "        return outputs.reshape(outputs.shape[0], output_steps, 2)\n",
    "    \n",
    "model = LR(input_dim = 50 * 2, out_dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322c657a-d533-4077-93e6-52e360c03dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(one_batch, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a605f-3f4f-404e-8de3-b8d780baefce",
   "metadata": {},
   "source": [
    "## 2. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a662c567-7d73-443c-b0e1-d0bbe706f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(hidden_dim, out_dim) #out_dim = 60*2\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, output_steps): \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(output_steps):\n",
    "            out = self.model(x)    \n",
    "            outputs.append(out)\n",
    "            x = torch.cat([x[:,2:],  out], dim = 1)\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "        return outputs.reshape(outputs.shape[0], output_steps, 2)\n",
    "     # def forward(self, x, output_steps): \n",
    "     #    x = x.reshape(x.shape[0], -1)\n",
    "     #    outputs = self.model(x)\n",
    "     #    return outputs.reshape(outputs.shape[0], output_steps, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5061510d-ec74-4712-8b5e-f1105becb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim = 50 * 2, out_dim = 2, hidden_dim = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a5cb570-a4c6-4625-874d-b0fbd04245ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(one_batch, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6058934-8775-4985-9b91-cabd4a6d4420",
   "metadata": {},
   "source": [
    "## 3. Temporal CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59440fe0-d71f-43d1-95ef-0738c747fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels, hidden_dim, kernel_size):\n",
    "        super(TCN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, hidden_dim, kernel_size = kernel_size, padding = (kernel_size - 1)//2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size - 1)//2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size - 1)//2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size - 1)//2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(hidden_dim, out_channels, kernel_size = kernel_size, padding = (kernel_size - 1)//2)\n",
    "        ) \n",
    "        \n",
    "      \n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "        outputs = self.model(x)\n",
    "        \n",
    "        return outputs.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f0afe1-c4b8-4dbf-9328-f07aadaaf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCN(input_channels = 2, out_channels = 2, hidden_dim = 16, kernel_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ad21a2-1219-44bc-9b8d-cf87175bad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a50f9e-4a11-4a5f-9609-1dede1325aab",
   "metadata": {},
   "source": [
    "## 4. Seq2Seq with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "924f6863-8324-4b0e-95f8-124e496adfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, \n",
    "                            hidden_size = hidden_dim, \n",
    "                            num_layers= num_layers, \n",
    "                            dropout = dropout_rate, \n",
    "                            batch_first = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, source):\n",
    "        \n",
    "        # hidden = (h, c)\n",
    "        # h, c: num_layers x bz x  hid_dim\n",
    "        # outputs: bz x input_length x hid_dim\n",
    "        outputs, hidden = self.lstm(source)\n",
    "        \n",
    "        return outputs, hidden\n",
    "    \n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, dropout_rate):\n",
    "\n",
    "        super(AttnDecoder, self).__init__()\n",
    "\n",
    "        # Learn the attention scores\n",
    "        self.attn = nn.Linear(hidden_dim + output_dim, 50)\n",
    "        \n",
    "        # Learn the final input to the decoder \n",
    "        self.attn_combine = nn.Linear(hidden_dim + output_dim, hidden_dim)\n",
    "        \n",
    "        # Decoder LSTM\n",
    "        self.lstm = nn.LSTM(input_size = hidden_dim, \n",
    "                            hidden_size = hidden_dim, \n",
    "                            num_layers= num_layers, \n",
    "                            dropout = dropout_rate, \n",
    "                            batch_first = True)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "      \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \n",
    "        h = hidden[0]\n",
    "        h = h.transpose(0,1).reshape(h.shape[1], -1)\n",
    "        \n",
    "        # Compute Attention Scores\n",
    "        attn_weights = F.softmax(self.attn(torch.cat([x, h], 1)), dim =1)\n",
    "        \n",
    "        # Calculate weighted sum of encoder hidden states     \n",
    "        attn_applied = torch.einsum(\"bl,blh->bh\", attn_weights, encoder_outputs)\n",
    "        \n",
    "        x = torch.cat((x, attn_applied), dim = 1)\n",
    "        x = self.attn_combine(x).unsqueeze(1)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        output, decoder_hidden= self.lstm(x, hidden)  \n",
    "        prediction = self.output_layer(output.float())\n",
    "        \n",
    "        return prediction.squeeze(1), decoder_hidden\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim = 2, output_dim = 2, hidden_dim = 128, num_layers = 1, dropout_rate = 0):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, num_layers, dropout_rate)\n",
    "        self.decoder = AttnDecoder(output_dim, hidden_dim, num_layers, dropout_rate)\n",
    "\n",
    "    def forward(self, source, target_length):\n",
    "\n",
    "        batch_size = source.size(0) \n",
    "        input_length = source.size(1) \n",
    "        \n",
    "        encoder_outputs, concat_hidden = self.encoder(source)\n",
    "        \n",
    "        # the last encoder hidden state is used as initial hidden state of the decoder\n",
    "        decoder_hidden = concat_hidden\n",
    "        # the first input to the decoder is last input position\n",
    "        decoder_output = source[:,-1]\n",
    "    \n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_length, 2)\n",
    "        for t in range(target_length):    \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_output, decoder_hidden, encoder_outputs)\n",
    "            outputs[:,t] = decoder_output   \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "75fe0da4-2fcd-44a3-bc8d-7e99c4d0e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "652b5bac-6f59-4df7-b998-2dfb2f194a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(one_batch, target_length = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160eb31f-a833-404a-9804-03769bf68d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
